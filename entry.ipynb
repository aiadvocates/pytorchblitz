{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.onnx as onnx\n","import matplotlib.pyplot as plt\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms"]},{"cell_type":"markdown","metadata":{},"source":["## DataSet"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# image classes\n","classes = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n","\n","# data used for training\n","training_data = datasets.FashionMNIST('data', train=True, download=True,\n","                        transform=transforms.Compose([transforms.ToTensor()]),\n","                        target_transform=transforms.Compose([\n","                            transforms.Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n","                        ])\n","                     )\n","\n","# data used for testing\n","test_data = datasets.FashionMNIST('data', train=False, download=True,\n","                        transform=transforms.Compose([transforms.ToTensor()]),\n","                        target_transform=transforms.Compose([\n","                            transforms.Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n","                        ])\n","                     )"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def draw_clothes(clothing):\n","    fig, axes = plt.subplots(7, 10, figsize=(18, 7),\n","                            subplot_kw={'xticks':[], 'yticks':[]},\n","                            gridspec_kw=dict(hspace=0.1, wspace=2.5))\n","    for i, ax in enumerate(axes.flat):\n","        X, y = clothing[i]\n","        ax.imshow(255 - X.reshape(28,28) * 255, cmap='gray')\n","        ax.set_title('{0}'.format(classes[torch.argmax(y).item()]))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["draw_clothes(training_data)"]},{"source":["# DataLoader"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# batch size\n","batch_size = 64\n","\n","# loader\n","train_dataloader = DataLoader(training_data, batch_size=batch_size, num_workers=0, pin_memory=True)\n","test_dataloader = DataLoader(test_data, batch_size=batch_size, num_workers=0, pin_memory=True)"]},{"source":["# Model, Loss, Optimizer"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# where to run\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print('Using {} device'.format(device))\n","\n","# model\n","model = nn.Sequential(\n","        nn.Flatten(),\n","        nn.Linear(28*28, 512),\n","        nn.ReLU(),\n","        nn.Linear(512, 512),\n","        nn.ReLU(),\n","        nn.Linear(512, len(classes)),\n","        nn.Softmax(dim=1)\n","    ).to(device)\n","    \n","print(model)\n","\n","# cost function used to determine best parameters\n","cost = torch.nn.BCELoss()\n","\n","# used to create optimal parameters\n","learning_rate = 1e-3\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"]},{"source":["# Optimization Loop\n","\n","Training run"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def train(dataloader, model, loss, optimizer):\n","    size = len(dataloader.dataset)\n","    for batch, (X, Y) in enumerate(dataloader):\n","        X, Y = X.to(device), Y.to(device)\n","        optimizer.zero_grad()\n","        pred = model(X)\n","        loss = cost(pred, Y)\n","        loss.backward()\n","        optimizer.step()\n","    \n","        if batch % 100 == 0:\n","            loss, current = loss.item(), batch * len(X)\n","            print(f'loss: {loss:>7f}  [{current:>5d}/{size:>5d}]')"]},{"source":["Test Run"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def test(dataloader, model):\n","    size = len(dataloader.dataset)\n","    model.eval()\n","    test_loss, correct = 0, 0\n","\n","    with torch.no_grad():\n","        for batch, (X, Y) in enumerate(dataloader):\n","            X, Y = X.to(device), Y.to(device)\n","            pred = model(X)\n","\n","            test_loss += cost(pred, Y).item()\n","            correct += (pred.argmax(1) == Y.argmax(1)).type(torch.float).sum().item()\n","\n","    test_loss /= size\n","    correct /= size\n","\n","    print(f'\\nTest Error:\\nacc: {(100*correct):>0.1f}%, avg loss: {test_loss:>8f}\\n')"]},{"source":["Loop"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["epochs = 5\n","\n","for t in range(epochs):\n","    print(f'Epoch {t+1}\\n-------------------------------')\n","    train(train_dataloader, model, cost, optimizer)\n","    test(test_dataloader, model)\n","print('Done!')"]},{"cell_type":"markdown","metadata":{},"source":["# Saving the model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# create dummy variable to traverse graph\n","x = torch.randint(255, (1, 28*28), dtype=torch.float).to(device) / 255\n","onnx.export(model, x, 'model.onnx')\n","print('Saved onnx model to model.onnx')\n","\n","# saving PyTorch Model Dictionary\n","torch.save(model.state_dict(), 'model.pth')\n","print('Saved PyTorch Model to model.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3},"version":"3.6.10-final"},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3,"kernelspec":{"name":"Python 3.6.10 64-bit","display_name":"Python 3.6.10 64-bit","metadata":{"interpreter":{"hash":"d412cf0cc95275da7f3e5a2cde727869a6beaae6991f4cbb39a087a6b0868edc"}}}}}